# -*- coding: utf-8 -*-
"""Breast cancer Prediction using ML

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/breast-cancer-prediction-using-ml-c537a18b-6ff2-4631-8849-6c1dda5b772b.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240927/auto/storage/goog4_request%26X-Goog-Date%3D20240927T082447Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dcb4f57277498ec2e876f18de0c4c9c48b1990612ab48789181fa92917c73dec80580ba04f64b55a4dd5857a9e55ec5b1c087902dedaec9eaa507c12fb7bcd04c4b9e491eb2de5b88042f09af639db10b9b32079e97e42b4ab320dcda828377745de545ff4f5b1abcbba5fecd0d995ebc74580e02e4a598737e7e3095335590741cae649c1465b7f4f3044446b98913d309e5e5f432eaa9e346a96fee41e9a6b68239c0234426fd10bc15bd6cf70f4d49cf2a426e71eb534955a244bf57eac2518dd069f5ca11c170a2bca58588458975391d0a6a55856ae004a239d74ffc501afecf16890dd6fa41927f21ae3b4051296b05dc180a88e2527085329ff3141eae

# **Import Libraries**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import sklearn.datasets
from scipy.stats import mode
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split , cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score , precision_score,confusion_matrix

# %matplotlib inline

import sys
sys.path.append('/kaggle/input/breast-cancer-dataset/breast cancer dataset.csv')

"""# **Data Collection & Processing**"""

# loading the data from sklearn
breast_cancer_dataset = sklearn.datasets.load_breast_cancer()

print(breast_cancer_dataset)

Datapath=('/kaggle/input/breast-cancer-dataset/breast cancer dataset.csv')
data=pd.read_csv(Datapath)

# loading the data to a data frame
data_frame = pd.DataFrame(breast_cancer_dataset.data, columns = breast_cancer_dataset.feature_names)
# print the first 5 rows of the dataframe
data_frame.head()

sns.barplot(x=data_frame.columns, y=data_frame.iloc[0])
plt.xticks(rotation=90)
plt.show()

"""# **Separating the features and target**"""

# adding the 'target' column to the data frame
data_frame['label'] = breast_cancer_dataset.target
# print last 5 rows of the dataframe
data_frame.tail()

X = data_frame.drop(columns='label', axis=1)
Y = data_frame['label']
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)
print(X.shape, X_train.shape, X_test.shape)

"""# **Model Training**"""

# Defining scoring metric for k-fold cross validation
def cv_scoring(estimator, X, Y):
    return accuracy_score(Y, estimator.predict(X))

# Initializing Models
models = {
    "SVC":SVC(),
    "Gaussian NB":GaussianNB(),
    "Random Forest":RandomForestClassifier(random_state=18),
    "Logistic Regression" : LogisticRegression(),
    "KNN" : KNeighborsClassifier()
}

# Producing cross validation score for the models
for model_name in models:
    model = models[model_name]
    scores = cross_val_score(model, X, Y, cv = 10,
                             n_jobs = -1,
                             scoring = cv_scoring)
    print("=="*30)
    print(model_name)
    print(f"Scores: {scores}")
    print(f"Mean Score: {np.mean(scores)}")

"""# **Model Evaluation**"""

# Training and testing SVM Classifier
svm_model = SVC()
svm_model.fit(X_train, Y_train)
preds = svm_model.predict(X_test)

print(f"Accuracy on train data by SVM Classifier\
: {accuracy_score(Y_train, svm_model.predict(X_train))*100}")

print(f"Accuracy on test data by SVM Classifier\
: {accuracy_score(Y_test, preds)*100}")
cf_matrix = confusion_matrix(Y_test, preds)
plt.figure(figsize=(12,8))
sns.heatmap(cf_matrix, annot=True)
plt.title("Confusion Matrix for SVM Classifier on Test Data")
plt.show()

# Training and testing Naive Bayes Classifier
nb_model = GaussianNB()
nb_model.fit(X_train, Y_train)
preds = nb_model.predict(X_test)
print(f"Accuracy on train data by Naive Bayes Classifier\
: {accuracy_score(Y_train, nb_model.predict(X_train))*100}")

print(f"Accuracy on test data by Naive Bayes Classifier\
: {accuracy_score(Y_test, preds)*100}")
cf_matrix = confusion_matrix(Y_test, preds)
plt.figure(figsize=(12,8))
sns.heatmap(cf_matrix, annot=True)
plt.title("Confusion Matrix for Naive Bayes Classifier on Test Data")
plt.show()

# Training and testing Random Forest Classifier
rf_model = RandomForestClassifier(random_state=18)
rf_model.fit(X_train, Y_train)
preds = rf_model.predict(X_test)
print(f"Accuracy on train data by Random Forest Classifier\
: {accuracy_score(Y_train, rf_model.predict(X_train))*100}")

print(f"Accuracy on test data by Random Forest Classifier\
: {accuracy_score(Y_test, preds)*100}")
cf_matrix = confusion_matrix(Y_test, preds)
plt.figure(figsize=(12,8))
sns.heatmap(cf_matrix, annot=True)
plt.title("Confusion Matrix for Random Forest Classifier on Test Data")
plt.show()

# Training and testing Logistic Regression
lg_model = LogisticRegression()
lg_model.fit(X_train, Y_train)
preds = lg_model.predict(X_test)
print(f"Accuracy on train data by Logistic Regression\
: {accuracy_score(Y_train, lg_model.predict(X_train))*100}")

print(f"Accuracy on test data by Logistic Regression\
: {accuracy_score(Y_test, preds)*100}")
cf_matrix = confusion_matrix(Y_test, preds)
plt.figure(figsize=(12,8))
sns.heatmap(cf_matrix, annot=True)
plt.title("Confusion Matrix for Logistic Regression on Test Data")
plt.show()

# Training and testing KNN
knn_model = KNeighborsClassifier()
knn_model.fit(X_train, Y_train)
preds = knn_model.predict(X_test)
print(f"Accuracy on train data by KNN\
: {accuracy_score(Y_train, knn_model.predict(X_train))*100}")

print(f"Accuracy on test data by KNN\
: {accuracy_score(Y_test, preds)*100}")
cf_matrix = confusion_matrix(Y_test, preds)
plt.figure(figsize=(12,8))
sns.heatmap(cf_matrix, annot=True)
plt.title("Confusion Matrix for KNN on Test Data")
plt.show()

"""# **Building a Predictive System**"""

model.fit(X_train, Y_train)

input_data = (13.54,14.36,87.46,566.3,0.08129,0.7866, 0.06664,0.04781,0.1885,0.05766,0.2699,0.7886,2.058,23.56,0.008462,0.0146,0.02387,0.01315,0.0198,0.0023,15.11,19.26,99.7,711.2,0.144,0.1773,0.239,0.1288,0.2977,0.07259)

# change the input data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the numpy array as we are predicting for one datapoint
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = model.predict(input_data_reshaped)
print(prediction)

if (prediction[0] == 0):
  print('The Breast cancer is Malignant')

else:
  print('The Breast Cancer is Benign')

import joblib

model.fit(X_train, Y_train)

# Save the trained model
joblib.dump(model, 'breast_cancer_model.pkl')

!pip install Flask
!pip install joblib scikit-learn

"""# **Model training & evaluation on 5 features**"""

import pandas as pd

# Load the data into a DataFrame (assuming you have the breast cancer dataset)
data_frame = pd.read_csv("/kaggle/input/breast-cancer-dataset/breast cancer dataset.csv")  # Replace with your file path

# Specify the 5 important features based on domain knowledge
important_features = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'concave points_mean']

# Extract the important features into a new DataFrame
selected_data_frame = data_frame[important_features]

# Print the first 5 rows of the new DataFrame with selected features
print(selected_data_frame.head())

# Now use this selected data for training your model
X_selected = selected_data_frame
Y = breast_cancer_dataset.target

# Split the data (for example)

X_train, X_test, Y_train, Y_test = train_test_split(X_selected, Y, test_size=0.2, random_state=42)

# Train your model as usual
model = SVC()
model.fit(X_train, Y_train)

# Make predictions and evaluate
preds = model.predict(X_test)

# Save the trained model
joblib.dump(model, 'breast_cancer.pkl')

